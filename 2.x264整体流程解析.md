## 编码流程分析

结合章节[x264的使用](./1.x264的使用.md)  可以知道x264的使用十分简单，x264_encoder_open完之后可以直接调用x264_encoder_encode进行编码操作

本章节主要对x264_encoder_encode函数的整体流程进行解析



x264_encoder_encode的流程可以简单分为以下几个步骤：

**1、图像初始化工作**

此部分涉及到一些图像初始化相关的工作，我们进行编码时编码数据是通过x264_picture_t传进去的，在x264_encoder_encode中会将x264_picture_t中指向的YUV**数据拷贝**一份到x264_frame_t中(**x264编码过程实际操作的是x264_frame_t，而不是x264_picture_t**)，同时会进行**格式转换**，x264中默认是对NV12格式进行编码的，如果x264_picture_t指向的YUV数据不是NV12的话还会进行格式转换转成NV12的。

得到x264_frame后，需要对x264_frame进行**像素对齐操作**，因为x264是以16x16宏块作为编码单元的，对于原始图片分辨率不是16的倍数的话需要**填充到16倍数**。*例如1920x1080的图像在x264中会被填充到1920x1088*   这部分填充了多少行/列的信息会写入到sps当中，因此解码器时能够知道当前图像的原始尺寸的。

如果开启自适应量化(AQ)会根据宏块的“能量值”初始化宏块的QP offset

同时还需要对x264_frame进行下采样生成宽高为原来一半的图像，在后续帧类型决策等部分需要用到这下采样后的图像

将当前x264_frame放到队列中等待帧类型决策



**2、帧类型决策**

我们知道帧大致可以可以分为IDR/I帧、P帧、B帧三种类型，帧类型决策就是**确定当前帧的类型**。 此过程受多个因素影响包括**用户强制编码关键帧**、**前后两帧的相似程度**、以及一些**编码参数**(GOP Size、B-Ref、OpenGOP、scenecut等等)等



**3、确定参考帧**

 P/B帧属于帧间编码，需要确定其参考帧是哪个，这部分工作就是在“确定参考帧”进行的。我们所知的SVC时域分层可以在此来实现(x264原生是不支持SVC时域分层的)



**4、帧级码率控制**

码率控制是一款编码器中很重要的组成部分，特别是对于编码码率要求比较严格的场景，编码器内部的码率控制显得尤为重要。

在x264中，在真正编码一帧之前当前帧会先经过码率控制模块，码率控制模块会根据当前待编码帧的复杂度、当前的码率情况、VBV情况、码控方式、maxQP等诸多原因计算出当前待编码帧的**帧级QP**，帧级QP很大程度上已经反应了当前帧所有宏块的平均量化程度。帧级QP越大，量化程度越大，质量损失越高（编码后质量越低），但码率越低。



**5、真正的编码过程**

此过程是整个编码流程成最重要也是最复杂的过程，帧间预测、帧内预测、变换量化、熵编码、去块滤波都是在此过程进行的



**6、收尾工作**

进行一些资源回收、更新码控控制等过程



## 源码分析

x264_encoder_encode的代码很多，大概5、600百行，本章尽量将注释写全一点，但代码中会有较多的关于写SPS/PPS/AUD/SEI的内容，这里不会做过多介绍。读者在阅读的时候尽量结合H264标准、x264源码多思考，理解一下

```c++
int     x264_encoder_encode( x264_t *h,
                             x264_nal_t **pp_nal, int *pi_nal,
                             x264_picture_t *pic_in,
                             x264_picture_t *pic_out )
{
    x264_t *thread_current, *thread_prev, *thread_oldest;
    int i_nal_type, i_nal_ref_idc, i_global_qp;
    int overhead = NALU_OVERHEAD;

#if HAVE_OPENCL
    if( h->opencl.b_fatal_error )
        return -1;
#endif

    if( h->i_thread_frames > 1 )
    {
      	// 如果开启帧级多线程编码会进入到这里  
        thread_prev    = h->thread[ h->i_thread_phase ];
        h->i_thread_phase = (h->i_thread_phase + 1) % h->i_thread_frames;
        thread_current = h->thread[ h->i_thread_phase ];
        thread_oldest  = h->thread[ (h->i_thread_phase + 1) % h->i_thread_frames ];
        thread_sync_context( thread_current, thread_prev );
        x264_thread_sync_ratecontrol( thread_current, thread_prev, thread_oldest );
        h = thread_current;
    }
    else
    {
        // 单线程或者Slice级多线程
        thread_current =
        thread_oldest  = h;
    }
    h->i_cpb_delay_pir_offset = h->i_cpb_delay_pir_offset_next;

    /* no data out */
    *pi_nal = 0;     // pi_nal和pp_nal分别指向编码输出的nal数量和nal单元，这里先初始化为空
    *pp_nal = NULL;

    /* ------------------- Setup new frame from picture -------------------- */
    if( pic_in != NULL )
    {
        if( h->lookahead->b_exit_thread )
        {
            x264_log( h, X264_LOG_ERROR, "lookahead thread is already stopped\n" );
            return -1;
        }

        /* 1: Copy the picture to a frame and move it to a buffer */
        /* fenc是x264编码所操作的对象，先pop出一个未使用的出来 */
        x264_frame_t *fenc = x264_frame_pop_unused( h, 0 );
        if( !fenc )
            return -1;  // 如果fenc为空，大概率是内存不足直接return
		
        /* 将pic_in指向的YUV以及一些字段拷贝到fenc中，里面可能会涉及到yuv格式转换，转成x264默认使用的NV12 */
        if( x264_frame_copy_picture( h, fenc, pic_in ) < 0 )
            return -1;
		
        /* 如果图像宽高不是16的倍数需要进行填充成16的倍数 */
        if( h->param.i_width != 16 * h->mb.i_mb_width ||
            h->param.i_height != 16 * h->mb.i_mb_height )
            x264_frame_expand_border_mod16( h, fenc );
		
        fenc->i_frame = h->frames.i_input++;

        if( fenc->i_frame == 0 )
            h->frames.i_first_pts = fenc->i_pts;
        if( h->frames.i_bframe_delay && fenc->i_frame == h->frames.i_bframe_delay )
            h->frames.i_bframe_delay_time = fenc->i_pts - h->frames.i_first_pts;

        if( h->param.b_vfr_input && fenc->i_pts <= h->frames.i_largest_pts )
            x264_log( h, X264_LOG_WARNING, "non-strictly-monotonic PTS\n" );

        h->frames.i_second_largest_pts = h->frames.i_largest_pts;
        h->frames.i_largest_pts = fenc->i_pts;

        if( (fenc->i_pic_struct < PIC_STRUCT_AUTO) || (fenc->i_pic_struct > PIC_STRUCT_TRIPLE) )
            fenc->i_pic_struct = PIC_STRUCT_AUTO;

        if( fenc->i_pic_struct == PIC_STRUCT_AUTO )
        {
#if HAVE_INTERLACED
            int b_interlaced = fenc->param ? fenc->param->b_interlaced : h->param.b_interlaced;
#else
            int b_interlaced = 0;
#endif
            if( b_interlaced )
            {
                int b_tff = fenc->param ? fenc->param->b_tff : h->param.b_tff;
                fenc->i_pic_struct = b_tff ? PIC_STRUCT_TOP_BOTTOM : PIC_STRUCT_BOTTOM_TOP;
            }
            else
                fenc->i_pic_struct = PIC_STRUCT_PROGRESSIVE;
        }

        if( h->param.rc.b_mb_tree && h->param.rc.b_stat_read )
        {
            if( x264_macroblock_tree_read( h, fenc, pic_in->prop.quant_offsets ) )
                return -1;
        }
        else // 如果有开启AQ的话此函数会初始化一些宏块QP的偏移值，具体参考‘AQ自适应量化章节’
            x264_adaptive_quant_frame( h, fenc, pic_in->prop.quant_offsets );

        if( pic_in->prop.quant_offsets_free )
            pic_in->prop.quant_offsets_free( pic_in->prop.quant_offsets );
		
        // 对图像进行下采样操作
        if( h->frames.b_have_lowres )
            x264_frame_init_lowres( h, fenc );

        /* 2: Place the frame into the queue for its slice type decision */
        /* 将当前帧Push到lookhead->next队列中准备进行‘帧类型决策’ */
        x264_lookahead_put_frame( h, fenc );

        if( h->frames.i_input <= h->frames.i_delay + 1 - h->i_thread_frames )
        {
            /* Nothing yet to encode, waiting for filling of buffers */
            /* 如果有延迟输出的话这里输出的帧数还没达到延迟的数量会先return */
            pic_out->i_type = X264_TYPE_AUTO;
            return 0;
        }
    }
    else
    {
        /* signal kills for lookahead thread */
        x264_pthread_mutex_lock( &h->lookahead->ifbuf.mutex );
        h->lookahead->b_exit_thread = 1;
        x264_pthread_cond_broadcast( &h->lookahead->ifbuf.cv_fill );
        x264_pthread_mutex_unlock( &h->lookahead->ifbuf.mutex );
    }

    h->i_frame++;
    /* 3: The picture is analyzed in the lookahead */
    if( !h->frames.current[0] )
        x264_lookahead_get_frames( h ); // 帧类型决策，决策当前待编码帧的帧类型

    if( !h->frames.current[0] && x264_lookahead_is_empty( h ) )
        return encoder_frame_end( thread_oldest, thread_current, pp_nal, pi_nal, pic_out );

    /* ------------------- Get frame to be encoded ------------------------- */
    /* 4: get picture to encode */
    /* 从h->frames.current队列中取出一帧，这里的帧时已经确定了帧类型了 */
    h->fenc = x264_frame_shift( h->frames.current );

    /* If applicable, wait for previous frame reconstruction to finish */
    if( h->param.b_sliced_threads )
        if( threadpool_wait_all( h ) < 0 )
            return -1;

    if( h->i_frame == 0 )
        h->i_reordered_pts_delay = h->fenc->i_reordered_pts;
    if( h->reconfig )
    {
        // 如果上层有调用x264_encoder_reconfig重新配置编码参数时，会在这里生效
        x264_encoder_reconfig_apply( h, &h->reconfig_h->param );
        h->reconfig = 0;
    }
    if( h->fenc->param )
    {
        x264_encoder_reconfig_apply( h, h->fenc->param );
        if( h->fenc->param->param_free )
        {
            h->fenc->param->param_free( h->fenc->param );
            h->fenc->param = NULL;
        }
    }
    x264_ratecontrol_zone_init( h );

    // ok to call this before encoding any frames, since the initial values of fdec have b_kept_as_ref=0
    // reference_update用于更新参考队列
    if( reference_update( h ) )
        return -1;
    /* fenc是用于存储编码前的帧，fdec是存储帧编码后再解码重构后的帧 */
    h->fdec->i_lines_completed = -1;

    if( !IS_X264_TYPE_I( h->fenc->i_type ) )
    {
        // 如果当前帧的类型不是IDR/I帧，但是参考队列中没有有效的帧，那么说明当前帧没有可以参考的帧，那么就将当前帧置为关键帧
        int valid_refs_left = 0;
        for( int i = 0; h->frames.reference[i]; i++ )
            if( !h->frames.reference[i]->b_corrupt )
                valid_refs_left++;
        /* No valid reference frames left: force an IDR. */
        if( !valid_refs_left )
        {
            h->fenc->b_keyframe = 1;
            h->fenc->i_type = X264_TYPE_IDR;
        }
    }

    if( h->fenc->b_keyframe )
    {
        // 更新一些关乎关键帧的信息
        h->frames.i_last_keyframe = h->fenc->i_frame;
        if( h->fenc->i_type == X264_TYPE_IDR )
        {
            h->i_frame_num = 0;
            h->frames.i_last_idr = h->fenc->i_frame;
        }
    }
    h->sh.i_mmco_command_count =
    h->sh.i_mmco_remove_from_end = 0;
    h->b_ref_reorder[0] =
    h->b_ref_reorder[1] = 0;
    // 确定poc，poc表示显示顺序，对于没有B帧的情况下这个值是递增的(遇到关键帧会重新从0开始)
    h->fdec->i_poc =
    h->fenc->i_poc = 2 * ( h->fenc->i_frame - X264_MAX( h->frames.i_last_idr, 0 ) );

    /* ------------------- Setup frame context ----------------------------- */
    /* 5: Init data dependent of frame type */
    /* 
     * 这里会根据帧的类型对参考队列进行不同的操作
     * i_nal_ref_idc就是nalu_header中nal_unit_idc这个值，范围0~3，数值越大表示重要程度越高，
     * i_nal_ref_idc值为0表示当前帧不作为参考帧(但反过来是不成立的，非参考帧的i_nal_ref_idc可以大于0)
     */
    if( h->fenc->i_type == X264_TYPE_IDR )
    {
        /* reset ref pictures */
        i_nal_type    = NAL_SLICE_IDR;
        i_nal_ref_idc = NAL_PRIORITY_HIGHEST;
        h->sh.i_type = SLICE_TYPE_I;
        // reference_reset，当前如果是IDR帧会清空参考帧队列(因为IDR后的帧是不能参考IDR之前的帧的)
        reference_reset( h );
        h->frames.i_poc_last_open_gop = -1;
    }
    else if( h->fenc->i_type == X264_TYPE_I )
    {
        i_nal_type    = NAL_SLICE;
        i_nal_ref_idc = NAL_PRIORITY_HIGH; /* Not completely true but for now it is (as all I/P are kept as ref)*/
        h->sh.i_type = SLICE_TYPE_I;
        reference_hierarchy_reset( h );
        if( h->param.b_open_gop )
            h->frames.i_poc_last_open_gop = h->fenc->b_keyframe ? h->fenc->i_poc : -1;
    }
    else if( h->fenc->i_type == X264_TYPE_P )
    {
        i_nal_type    = NAL_SLICE;
        i_nal_ref_idc = NAL_PRIORITY_HIGH; /* Not completely true but for now it is (as all I/P are kept as ref)*/
        h->sh.i_type = SLICE_TYPE_P;
        reference_hierarchy_reset( h );
        h->frames.i_poc_last_open_gop = -1;
    }
    else if( h->fenc->i_type == X264_TYPE_BREF )
    {
        i_nal_type    = NAL_SLICE;
        i_nal_ref_idc = h->param.i_bframe_pyramid == X264_B_PYRAMID_STRICT ? NAL_PRIORITY_LOW : NAL_PRIORITY_HIGH;
        h->sh.i_type = SLICE_TYPE_B;
        reference_hierarchy_reset( h );
    }
    else    /* B frame */
    {
        i_nal_type    = NAL_SLICE;
        i_nal_ref_idc = NAL_PRIORITY_DISPOSABLE;
        h->sh.i_type = SLICE_TYPE_B;
    }

    h->fdec->i_type = h->fenc->i_type;
    h->fdec->i_frame = h->fenc->i_frame;
    /*
     * NAL_PRIORITY_DISPOSABLE = 0
     * 确定当前帧是否可以作为参考帧b_kept_as_ref
     * 这里不能弄混，‘可作为参考帧’并不是‘一定是参考帧’，可能后续的帧不会去参考它（具体的参考关系可以自己实现一套）
     */
    h->fenc->b_kept_as_ref =
    h->fdec->b_kept_as_ref = i_nal_ref_idc != NAL_PRIORITY_DISPOSABLE && h->param.i_keyint_max > 1;

    h->fdec->mb_info = h->fenc->mb_info;
    h->fdec->mb_info_free = h->fenc->mb_info_free;
    h->fenc->mb_info = NULL;
    h->fenc->mb_info_free = NULL;

    h->fdec->i_pts = h->fenc->i_pts;
    if( h->frames.i_bframe_delay )
    {
        int64_t *prev_reordered_pts = thread_current->frames.i_prev_reordered_pts;
        h->fdec->i_dts = h->i_frame > h->frames.i_bframe_delay
                       ? prev_reordered_pts[ (h->i_frame - h->frames.i_bframe_delay) % h->frames.i_bframe_delay ]
                       : h->fenc->i_reordered_pts - h->frames.i_bframe_delay_time;
        prev_reordered_pts[ h->i_frame % h->frames.i_bframe_delay ] = h->fenc->i_reordered_pts;
    }
    else
        h->fdec->i_dts = h->fenc->i_reordered_pts;
    if( h->fenc->i_type == X264_TYPE_IDR )
        h->i_last_idr_pts = h->fdec->i_pts;

    /* ------------------- Init                ----------------------------- */
    /* build ref list 0/1 */
    /* 确定当前帧的参考帧 */
    reference_build_list( h, h->fdec->i_poc );

    /* ---------------------- Write the bitstream -------------------------- */
    /* Init bitstream context */
    if( h->param.b_sliced_threads )
    {
        for( int i = 0; i < h->param.i_threads; i++ )
        {
            bs_init( &h->thread[i]->out.bs, h->thread[i]->out.p_bitstream, h->thread[i]->out.i_bitstream );
            h->thread[i]->out.i_nal = 0;
        }
    }
    else
    {
        bs_init( &h->out.bs, h->out.p_bitstream, h->out.i_bitstream );
        h->out.i_nal = 0;
    }

    if( h->param.b_aud )
    {
        // 写AUD,这里NALU不是很重要可以忽略
        int pic_type;

        if( h->sh.i_type == SLICE_TYPE_I )
            pic_type = 0;
        else if( h->sh.i_type == SLICE_TYPE_P )
            pic_type = 1;
        else if( h->sh.i_type == SLICE_TYPE_B )
            pic_type = 2;
        else
            pic_type = 7;

        nal_start( h, NAL_AUD, NAL_PRIORITY_DISPOSABLE );
        bs_write( &h->out.bs, 3, pic_type );
        bs_rbsp_trailing( &h->out.bs );
        bs_flush( &h->out.bs );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + NALU_OVERHEAD;
    }

    h->i_nal_type = i_nal_type;
    h->i_nal_ref_idc = i_nal_ref_idc;

    if( h->param.b_intra_refresh )
    {
        if( IS_X264_TYPE_I( h->fenc->i_type ) )
        {
            h->fdec->i_frames_since_pir = 0;
            h->b_queued_intra_refresh = 0;
            /* PIR is currently only supported with ref == 1, so any intra frame effectively refreshes
             * the whole frame and counts as an intra refresh. */
            h->fdec->f_pir_position = h->mb.i_mb_width;
        }
        else if( h->fenc->i_type == X264_TYPE_P )
        {
            int pocdiff = (h->fdec->i_poc - h->fref[0][0]->i_poc)/2;
            float increment = X264_MAX( ((float)h->mb.i_mb_width-1) / h->param.i_keyint_max, 1 );
            h->fdec->f_pir_position = h->fref[0][0]->f_pir_position;
            h->fdec->i_frames_since_pir = h->fref[0][0]->i_frames_since_pir + pocdiff;
            if( h->fdec->i_frames_since_pir >= h->param.i_keyint_max ||
                (h->b_queued_intra_refresh && h->fdec->f_pir_position + 0.5 >= h->mb.i_mb_width) )
            {
                h->fdec->f_pir_position = 0;
                h->fdec->i_frames_since_pir = 0;
                h->b_queued_intra_refresh = 0;
                h->fenc->b_keyframe = 1;
            }
            h->fdec->i_pir_start_col = h->fdec->f_pir_position+0.5;
            h->fdec->f_pir_position += increment * pocdiff;
            h->fdec->i_pir_end_col = h->fdec->f_pir_position+0.5;
            /* If our intra refresh has reached the right side of the frame, we're done. */
            if( h->fdec->i_pir_end_col >= h->mb.i_mb_width - 1 )
            {
                h->fdec->f_pir_position = h->mb.i_mb_width;
                h->fdec->i_pir_end_col = h->mb.i_mb_width - 1;
            }
        }
    }

    if( h->fenc->b_keyframe )
    {
        /* Write SPS and PPS， 写SPS、PPS */
        if( h->param.b_repeat_headers )
        {
            /* generate sequence parameters */
            nal_start( h, NAL_SPS, NAL_PRIORITY_HIGHEST );
            x264_sps_write( &h->out.bs, h->sps );
            if( nal_end( h ) )
                return -1;
            /* Pad AUD/SPS to 256 bytes like Panasonic */
            if( h->param.i_avcintra_class )
                h->out.nal[h->out.i_nal-1].i_padding = 256 - bs_pos( &h->out.bs ) / 8 - 2*NALU_OVERHEAD;
            overhead += h->out.nal[h->out.i_nal-1].i_payload + h->out.nal[h->out.i_nal-1].i_padding + NALU_OVERHEAD;

            /* generate picture parameters */
            nal_start( h, NAL_PPS, NAL_PRIORITY_HIGHEST );
            x264_pps_write( &h->out.bs, h->sps, h->pps );
            if( nal_end( h ) )
                return -1;
            if( h->param.i_avcintra_class )
            {
                int total_len = 256;
                /* Sony XAVC uses an oversized PPS instead of SEI padding */
                if( h->param.i_avcintra_flavor == X264_AVCINTRA_FLAVOR_SONY )
                    total_len += h->param.i_height == 1080 ? 18*512 : 10*512;
                h->out.nal[h->out.i_nal-1].i_padding = total_len - h->out.nal[h->out.i_nal-1].i_payload - NALU_OVERHEAD;
            }
            overhead += h->out.nal[h->out.i_nal-1].i_payload + h->out.nal[h->out.i_nal-1].i_padding + NALU_OVERHEAD;
        }

        /* when frame threading is used, buffering period sei is written in encoder_frame_end */
        if( h->i_thread_frames == 1 && h->sps->vui.b_nal_hrd_parameters_present )
        {
            x264_hrd_fullness( h );
            nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
            x264_sei_buffering_period_write( h, &h->out.bs );
            if( nal_end( h ) )
               return -1;
            overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
        }
    }

    /* write extra sei， 写SEI可以大致看一下，x264会将一些编码参数写到SEI中 */
    for( int i = 0; i < h->fenc->extra_sei.num_payloads; i++ )
    {
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        x264_sei_write( &h->out.bs, h->fenc->extra_sei.payloads[i].payload, h->fenc->extra_sei.payloads[i].payload_size,
                        h->fenc->extra_sei.payloads[i].payload_type );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
        if( h->fenc->extra_sei.sei_free )
        {
            h->fenc->extra_sei.sei_free( h->fenc->extra_sei.payloads[i].payload );
            h->fenc->extra_sei.payloads[i].payload = NULL;
        }
    }

    if( h->fenc->extra_sei.sei_free )
    {
        h->fenc->extra_sei.sei_free( h->fenc->extra_sei.payloads );
        h->fenc->extra_sei.payloads = NULL;
        h->fenc->extra_sei.sei_free = NULL;
    }

    if( h->fenc->b_keyframe )
    {
        /* Avid's decoder strictly wants two SEIs for AVC-Intra so we can't insert the x264 SEI */
        if( h->param.b_repeat_headers && h->fenc->i_frame == 0 && !h->param.i_avcintra_class )
        {
            /* identify ourself */
            nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
            if( x264_sei_version_write( h, &h->out.bs ) )
                return -1;
            if( nal_end( h ) )
                return -1;
            overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
        }

        if( h->fenc->i_type != X264_TYPE_IDR )
        {
            int time_to_recovery = h->param.b_open_gop ? 0 : X264_MIN( h->mb.i_mb_width - 1, h->param.i_keyint_max ) + h->param.i_bframe - 1;
            nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
            x264_sei_recovery_point_write( h, &h->out.bs, time_to_recovery );
            if( nal_end( h ) )
                return -1;
            overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
        }
    }

    if( h->param.i_frame_packing >= 0 && (h->fenc->b_keyframe || h->param.i_frame_packing == 5) )
    {
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        x264_sei_frame_packing_write( h, &h->out.bs );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
    }

    if( h->param.i_alternative_transfer != 2 )
    {
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        x264_sei_alternative_transfer_write( h, &h->out.bs );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
    }

    /* generate sei pic timing */
    if( h->sps->vui.b_pic_struct_present || h->sps->vui.b_nal_hrd_parameters_present )
    {
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        x264_sei_pic_timing_write( h, &h->out.bs );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
    }

    /* As required by Blu-ray. */
    if( !IS_X264_TYPE_B( h->fenc->i_type ) && h->b_sh_backup )
    {
        h->b_sh_backup = 0;
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        x264_sei_dec_ref_pic_marking_write( h, &h->out.bs );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;
    }

    if( h->fenc->b_keyframe && h->param.b_intra_refresh )
        h->i_cpb_delay_pir_offset_next = h->fenc->i_cpb_delay;

    /* Filler space: 10 or 18 SEIs' worth of space, depending on resolution */
    if( h->param.i_avcintra_class && h->param.i_avcintra_flavor != X264_AVCINTRA_FLAVOR_SONY )
    {
        /* Write an empty filler NAL to mimic the AUD in the P2 format*/
        nal_start( h, NAL_FILLER, NAL_PRIORITY_DISPOSABLE );
        x264_filler_write( h, &h->out.bs, 0 );
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + NALU_OVERHEAD;

        /* All lengths are magic lengths that decoders expect to see */
        /* "UMID" SEI */
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        if( x264_sei_avcintra_umid_write( h, &h->out.bs ) < 0 )
            return -1;
        if( nal_end( h ) )
            return -1;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + SEI_OVERHEAD;

        int unpadded_len;
        int total_len;
        if( h->param.i_height == 1080 )
        {
            unpadded_len = 5780;
            total_len = 17*512;
        }
        else
        {
            unpadded_len = 2900;
            total_len = 9*512;
        }
        /* "VANC" SEI */
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        if( x264_sei_avcintra_vanc_write( h, &h->out.bs, unpadded_len ) < 0 )
            return -1;
        if( nal_end( h ) )
            return -1;

        h->out.nal[h->out.i_nal-1].i_padding = total_len - h->out.nal[h->out.i_nal-1].i_payload - SEI_OVERHEAD;
        overhead += h->out.nal[h->out.i_nal-1].i_payload + h->out.nal[h->out.i_nal-1].i_padding + SEI_OVERHEAD;
    }

    /* Init the rate control */
    /* FIXME: Include slice header bit cost. */
    // 帧级码率控制部分，会获取一个帧级QP，就是下面的i_global_qp
    x264_ratecontrol_start( h, h->fenc->i_qpplus1, overhead*8 );
    i_global_qp = x264_ratecontrol_qp( h );

    pic_out->i_qpplus1 =
    h->fdec->i_qpplus1 = i_global_qp + 1;

    if( h->param.rc.b_stat_read && h->sh.i_type != SLICE_TYPE_I )
    {
        x264_reference_build_list_optimal( h );
        reference_check_reorder( h );
    }

    if( h->i_ref[0] )
        h->fdec->i_poc_l0ref0 = h->fref[0][0]->i_poc;

    /* ------------------------ Create slice header  ----------------------- */
    /* 代码执行到这里基本Slice Header中的信息都能确定了，在这里做一些slice_header字段的初始化工作 */
    slice_init( h, i_nal_type, i_global_qp );

    /*------------------------- Weights -------------------------------------*/
    if( h->sh.i_type == SLICE_TYPE_B )
        x264_macroblock_bipred_init( h );
	
    // 加权预测初始化
    weighted_pred_init( h );

    if( i_nal_ref_idc != NAL_PRIORITY_DISPOSABLE )
        h->i_frame_num++;

    /* Write frame */
    h->i_threadslice_start = 0;
    h->i_threadslice_end = h->mb.i_mb_height;
    /*
     * 这里会根据多线程/单线程的情况进入到不同的条件中(详细可以参考多线程分析那个章节)
     * slices_write是x264_encoder_encode的核心函数，帧编码过程都在此函数中
     */
    if( h->i_thread_frames > 1 )
    {
        // 帧级并行会到这个条件，在子线程中执行slices_write
        x264_threadpool_run( h->threadpool, (void*)slices_write, h);
        h->b_thread_active = 1;
    }
    else if( h->param.b_sliced_threads )
    {
        // Slice并行会到这个条件，执行thread_slices_write
        if( threaded_slices_write( h ) )
            return -1;
    }
    else // 单线程的话就进入到这个条件直接执行slices_write
        if( (intptr_t)slices_write( h ) )
            return -1;


    return encoder_frame_end( thread_oldest, thread_current, pp_nal, pi_nal, pic_out );
}

```





#### 部分调用函数解析

这里会抽出一些x264_encoder_encode中调用的函数进行分析，有些函数后续章节会介绍这里就不进行分析了



**在x264源码中会经常看到x264_frame_push_unused，x264_frame_pop_unused的函数或者h->fenc、h->fdec的变量，这里做一个介绍**

每个x264_t实例都拥有一个队列，即h->frames.unused[2]，存储着没有被用到的x264_frame_t，其中h->frames.unused[0]存储着待编码的x264_frame_t(如h->fenc就是这种类型)，h->frames.unused[1]存储着解码重建后的x264_frame_t（h->fdec就是这种类型）

```c++
/* Unused frames: 0 = fenc, 1 = fdec */
x264_frame_t **unused[2];
```

h->fenc、h->fdec都是x264_frame_t*类型

h->fenc，存储的是**待编码**的数据(包含YUV数据，以及还有很多其他信息，如frame_num，frame_type等等)

h->fdec，存储的是**解码重建**后的数据(与上面一样)

x264中出于内存管理的便捷性和安全性考虑，对x264_frame_t采用了“**引用计数**”的管理方式，当x264_frame_t的引用计数为0时会push进h->frames.unused队列中

```c++
typedef uint8_t  pixel;

static int frame_internal_csp( int external_csp )
{
    // 确定x264_frame中的YUV存储格式
    int csp = external_csp & X264_CSP_MASK;
    if( csp == X264_CSP_I400 )
        return X264_CSP_I400;
    if( csp >= X264_CSP_I420 && csp < X264_CSP_I422 )
        return X264_CSP_NV12;  // 对于YUV420来说都会转为NV12
    if( csp >= X264_CSP_I422 && csp < X264_CSP_I444 )
        return X264_CSP_NV16;  // 对于YUV422来说会转为NV16
    if( csp >= X264_CSP_I444 && csp <= X264_CSP_RGB )
        return X264_CSP_I444;
    return X264_CSP_NONE;
}

typedef struct x264_frame{
    // 这里主要介绍几个字段
    // ......
    uint8_t b_fdec;   // 是否是解码重构的x264_frame，对于h->fenc此字段为0，h->fdec此字段为1
    int b_kept_as_ref; // 当前帧是否可作为参考帧
    int     i_csp;    // 当前存储YUV的格式，正常对于YUV420类型来说这个值为X264_CSP_I420,详细见frame_internal_csp函数
    pixel *plane[3];  // 指向YUV数据，对于YUV420类型来说，plane[0]指向Y，plane[1]指向UV， x264_frame_t中YUV是NV12的形式在一起的，因此UV分量是放在一起的
    int     i_reference_count; /* 引用计数 number of threads using this frame (not necessarily the number of pointers) */
    // ......
} x264_frame_t
```



**x264_frame_pop_unused**

```c++
/*
 * 在x264_encoder_encode开始的时候会执行一行x264_frame_t *fenc = x264_frame_pop_unused( h, 0 );
 * 以及在reference_update中会执行h->fdec = x264_frame_pop_unused( h, 1 );
 * 作用是从h->frames.ununsed[]中pop一帧出来给fenc/h->fdec使用
 */

// 参数2表示是否是重建帧，对于h->fenc来说传0，对于h->fdec来说传1
x264_frame_t *x264_frame_pop_unused( x264_t *h, int b_fdec )
{
    x264_frame_t *frame;
    if( h->frames.unused[b_fdec][0] )  // 如果对应的队列中第一个位置不为NULL(有空闲的帧)直接pop出来即可
        frame = x264_frame_pop( h->frames.unused[b_fdec] );
    else
        frame = frame_new( h, b_fdec ); // 如果对应的队列中第一个位置为NULL(表示没有空闲的帧)，需要重新申请构建一个
    if( !frame )
        return NULL;
    // 一些字段的初始化，特别是“引用技术”置位1
    frame->b_last_minigop_bframe = 0;
    frame->i_reference_count = 1;  // 引用计数初始化为1
    frame->b_intra_calculated = 0;
    frame->b_scenecut = 1;
    frame->b_keyframe = 0;
    frame->b_corrupt = 0;
    frame->i_slice_count = h->param.b_sliced_threads ? h->param.i_threads : 1;

    memset( frame->weight, 0, sizeof(frame->weight) );
    memset( frame->f_weighted_cost_delta, 0, sizeof(frame->f_weighted_cost_delta) );

    return frame;
}

x264_frame_t *x264_frame_pop( x264_frame_t **list )
{
    // 取出list中最后一个非NULL的x264_frame
    x264_frame_t *frame;
    int i = 0;
    assert( list[0] );
    while( list[i+1] ) i++;
    frame = list[i];
    list[i] = NULL;
    return frame;
}

/*
 *  frame_new中会做一些内存申请，字段初始化等工作代码有200+行，这里就不贴出来介绍了
 */
```



**x264_frame_push_unused**

```c++
/*
 *  在encoder_frame_end中会调用x264_frame_push_unused( thread_current, h->fenc );
 *  在reference_update中也会调用x264_frame_push_unused( h, h->fdec );
 *  这里主要是为了资源的回收(对引用计数-1)
 */

void x264_frame_push_unused( x264_t *h, x264_frame_t *frame )
{
    // 对引用计数-1，如果引用计数为0则放到对应的h->frames.unused的空闲队列的尾部
    assert( frame->i_reference_count > 0 );
    frame->i_reference_count--;
    if( frame->i_reference_count == 0 )
        x264_frame_push( h->frames.unused[frame->b_fdec], frame );
}
```



**// reference_update**

更新参考队列

```c++
/*
 * h->frames.reference是一个数组，用来存储参考帧的
 */
static inline int reference_update( x264_t *h )
{
    /* 
     * h->fdec存储着前面一帧编码后的重建帧，这与我们正常思维有点不一样(正常我们觉得编码完当前帧后会顺带将当前帧的重建帧更新到参考队列中)
     * 然而x264是在编码当前帧的时候将前面一帧解码重建后的图像更新到参考队列中
     */
    if( !h->fdec->b_kept_as_ref )  // 所以代码执行到这里h->fdec存储的还是上一帧编码后的重建帧
    {
        // 如果上一帧不可作为参考帧则到当前条件下
        if( h->i_thread_frames > 1 )
        {
            x264_frame_push_unused( h, h->fdec );
            h->fdec = x264_frame_pop_unused( h, 1 );
            if( !h->fdec )
                return -1;
        }
        return 0;
    }
    // 如果上一帧可以作为参考帧则继续往下执行
    /* apply mmco from previous frame. */
    for( int i = 0; i < h->sh.i_mmco_command_count; i++ )
        for( int j = 0; h->frames.reference[j]; j++ )
            if( h->frames.reference[j]->i_poc == h->sh.mmco[i].i_poc )
                x264_frame_push_unused( h, x264_frame_shift( &h->frames.reference[j] ) );

    /* move frame in the buffer */
    // 将上一帧重建帧更新到参考队列中
    x264_frame_push( h->frames.reference, h->fdec );
  	// 如果参考队列中的参考帧数量超过最大值sps->i_num_ref_frames则从中移除最旧的一个
    if( h->frames.reference[h->sps->i_num_ref_frames] )
        x264_frame_push_unused( h, x264_frame_shift( h->frames.reference ) );
    /*
     * pop出一个新的frame给h->fdec，此时这个h->fdec就是用来存储当前编码帧的解码重建帧
     * 而不是上一帧的重建帧了
     */
    h->fdec = x264_frame_pop_unused( h, 1 );
    if( !h->fdec )
        return -1;
    return 0;
}
```



**//  reference_reset**

清空参考队列中的参考帧

```c++
x264_frame_t *x264_frame_pop( x264_frame_t **list )
{
    // 这块代码比较简单，就是去除list数组中的最后一个非NULL值
    x264_frame_t *frame;
    int i = 0;
    assert( list[0] );
    while( list[i+1] ) i++;
    frame = list[i];
    list[i] = NULL;
    return frame;
}

static inline void reference_reset( x264_t *h )
{
    // while循环回收 h->frames.reference中的帧
    while( h->frames.reference[0] ) 
        x264_frame_push_unused( h, x264_frame_pop( h->frames.reference ) );
    h->fdec->i_poc =
    h->fenc->i_poc = 0;
}
```



**// reference_build_list**

寻找参考帧

```c++

static inline void reference_build_list( x264_t *h, int i_poc )
{
    int b_ok;

    /* build ref list 0/1 */
    h->mb.pic.i_fref[0] = h->i_ref[0] = 0;  //h->i_ref[0]表示当前帧向前参考多少帧，先初始化为0
    h->mb.pic.i_fref[1] = h->i_ref[1] = 0;  //h->i_ref[1]表示当前帧向后参考多少帧，也先初始化为0
    if( h->sh.i_type == SLICE_TYPE_I ) // 如果当前帧是IDR/I帧，不需要参考帧直接return
        return;

    for( int i = 0; h->frames.reference[i]; i++ )
    {
        if( h->frames.reference[i]->b_corrupt ) // 如果当前帧是无效的continous
            continue;
        if( h->frames.reference[i]->i_poc < i_poc )  // poc在当前帧之前的
            h->fref[0][h->i_ref[0]++] = h->frames.reference[i];
        else if( h->frames.reference[i]->i_poc > i_poc )  // poc在当前帧之后的
            h->fref[1][h->i_ref[1]++] = h->frames.reference[i];
    }

    if( h->sh.i_mmco_remove_from_end )
    {
        /* Order ref0 for MMCO remove */
        do
        {
            b_ok = 1;
            for( int i = 0; i < h->i_ref[0] - 1; i++ )
            {
                if( h->fref[0][i]->i_frame < h->fref[0][i+1]->i_frame )
                {
                    XCHG( x264_frame_t*, h->fref[0][i], h->fref[0][i+1] );
                    b_ok = 0;
                    break;
                }
            }
        } while( !b_ok );

        for( int i = h->i_ref[0]-1; i >= h->i_ref[0] - h->sh.i_mmco_remove_from_end; i-- )
        {
            int diff = h->i_frame_num - h->fref[0][i]->i_frame_num;
            h->sh.mmco[h->sh.i_mmco_command_count].i_poc = h->fref[0][i]->i_poc;
            h->sh.mmco[h->sh.i_mmco_command_count++].i_difference_of_pic_nums = diff;
        }
    }

    /* Order reference lists by distance from the current frame. */
    for( int list = 0; list < 2; list++ )
    {
        h->fref_nearest[list] = h->fref[list][0];
        do
        {
            b_ok = 1;
            for( int i = 0; i < h->i_ref[list] - 1; i++ )
            {
                if( list ? h->fref[list][i+1]->i_poc < h->fref_nearest[list]->i_poc
                         : h->fref[list][i+1]->i_poc > h->fref_nearest[list]->i_poc )
                    h->fref_nearest[list] = h->fref[list][i+1];
                /* 在多参考帧的情况下，会对参考帧进行排序，让离当前帧更近的排在前面 */
                if( reference_distance( h, h->fref[list][i] ) > reference_distance( h, h->fref[list][i+1] ) )
                {
                    // 调换两个位置
                    XCHG( x264_frame_t*, h->fref[list][i], h->fref[list][i+1] );
                    b_ok = 0;
                    break;
                }
            }
        } while( !b_ok );
    }

    reference_check_reorder( h );

    // 修正h->i_ref[0]、h->i_ref[1]的值，必须小于上限值
    h->i_ref[1] = X264_MIN( h->i_ref[1], h->frames.i_max_ref1 );
    h->i_ref[0] = X264_MIN( h->i_ref[0], h->frames.i_max_ref0 );
    h->i_ref[0] = X264_MIN( h->i_ref[0], h->param.i_frame_reference ); // if reconfig() has lowered the limit

    /* For Blu-ray compliance, don't reference frames outside of the minigop. */
    if( IS_X264_TYPE_B( h->fenc->i_type ) && h->param.b_bluray_compat )
        h->i_ref[0] = X264_MIN( h->i_ref[0], IS_X264_TYPE_B( h->fref[0][0]->i_type ) + 1 );

    /* add duplicates */
    if( h->fenc->i_type == X264_TYPE_P )
    {
        int idx = -1;
        if( h->param.analyse.i_weighted_pred >= X264_WEIGHTP_SIMPLE )
        {
            x264_weight_t w[3];
            w[1].weightfn = w[2].weightfn = NULL;
            if( h->param.rc.b_stat_read )
                x264_ratecontrol_set_weights( h, h->fenc );

            if( !h->fenc->weight[0][0].weightfn )
            {
                h->fenc->weight[0][0].i_denom = 0;
                SET_WEIGHT( w[0], 1, 1, 0, -1 );
                idx = weighted_reference_duplicate( h, 0, w );
            }
            else
            {
                if( h->fenc->weight[0][0].i_scale == 1<<h->fenc->weight[0][0].i_denom )
                {
                    SET_WEIGHT( h->fenc->weight[0][0], 1, 1, 0, h->fenc->weight[0][0].i_offset );
                }
                weighted_reference_duplicate( h, 0, x264_weight_none );
                if( h->fenc->weight[0][0].i_offset > -128 )
                {
                    w[0] = h->fenc->weight[0][0];
                    w[0].i_offset--;
                    h->mc.weight_cache( h, &w[0] );
                    idx = weighted_reference_duplicate( h, 0, w );
                }
            }
        }
        h->mb.ref_blind_dupe = idx;
    }

    assert( h->i_ref[0] + h->i_ref[1] <= X264_REF_MAX );
    // 将h->i_ref赋值到h->mb.pic_i_fref中，在宏块分析阶段会用到这个h->mb.pic_i_fref
    h->mb.pic.i_fref[0] = h->i_ref[0]; 
    h->mb.pic.i_fref[1] = h->i_ref[1];
}
```



**// encoder_frame_end**

encoder_frame_end会做一些编码的收尾工作，包括计算编码后帧大小、更新码控、以及一些参数统计，结果输出等

```c++
static int encoder_frame_end( x264_t *h, x264_t *thread_current,
                              x264_nal_t **pp_nal, int *pi_nal,
                              x264_picture_t *pic_out )
{
    char psz_message[80];

    if( !h->param.b_sliced_threads && h->b_thread_active )
    {
        /* 如果开启帧级多线程的话会进入到这里，阻塞等待“oldest thread”返回，详细见“x264多线程”章节 */
        h->b_thread_active = 0;
        if( (intptr_t)x264_threadpool_wait( h->threadpool, h ) )
            return -1;
    }
    if( !h->out.i_nal )
    {
        // 如果i_nal数量为0直接返回，正常情况下单线程是不会进入到这里的，多线程才会
        pic_out->i_type = X264_TYPE_AUTO;
        return 0;
    }

    x264_emms();

    /* generate buffering period sei and insert it into place */
    /* 写sei的操作 */
    if( h->i_thread_frames > 1 && h->fenc->b_keyframe && h->sps->vui.b_nal_hrd_parameters_present )
    {
        x264_hrd_fullness( h );
        nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
        x264_sei_buffering_period_write( h, &h->out.bs );
        if( nal_end( h ) )
           return -1;
        /* buffering period sei must follow AUD, SPS and PPS and precede all other SEIs */
        int idx = 0;
        while( h->out.nal[idx].i_type == NAL_AUD ||
               h->out.nal[idx].i_type == NAL_SPS ||
               h->out.nal[idx].i_type == NAL_PPS )
            idx++;
        x264_nal_t nal_tmp = h->out.nal[h->out.i_nal-1];
        memmove( &h->out.nal[idx+1], &h->out.nal[idx], (h->out.i_nal-idx-1)*sizeof(x264_nal_t) );
        h->out.nal[idx] = nal_tmp;
    }
	// 计算当前编码后的帧大小(包括了startcode和nalu_header)
    int frame_size = encoder_encapsulate_nals( h, 0 );
    if( frame_size < 0 )
        return -1;

    /* Set output picture properties */
    // 将一些编码输出信息赋值给pic_out，让上层调用x264_encoder_encode的能知道一些编码信息
    pic_out->i_type = h->fenc->i_type;

    pic_out->b_keyframe = h->fenc->b_keyframe;
    pic_out->i_pic_struct = h->fenc->i_pic_struct;

    pic_out->i_pts = h->fdec->i_pts;
    pic_out->i_dts = h->fdec->i_dts;

    if( pic_out->i_pts < pic_out->i_dts )
        x264_log( h, X264_LOG_WARNING, "invalid DTS: PTS is less than DTS\n" );

    pic_out->opaque = h->fenc->opaque;

    pic_out->img.i_csp = h->fdec->i_csp;
#if HIGH_BIT_DEPTH
    pic_out->img.i_csp |= X264_CSP_HIGH_DEPTH;
#endif
    pic_out->img.i_plane = h->fdec->i_plane;
    for( int i = 0; i < pic_out->img.i_plane; i++ )
    {
        pic_out->img.i_stride[i] = h->fdec->i_stride[i] * SIZEOF_PIXEL;
        pic_out->img.plane[i] = (uint8_t*)h->fdec->plane[i];
    }
    // “回收” h->fenc，不然会造成内存泄露
    x264_frame_push_unused( thread_current, h->fenc );

    /* ---------------------- Update encoder state ------------------------- */

    /* update rc */
    /* 
     * 更新码控，此函数具体细节在“码率控制”章节会讲到
     * 这个filler为“填充”，只有在使用NAL_HRD_CBR的是有会有有效，可以理解为Constant Bitrate(固定码率)
     * 对于一些实际编码码率不足的情况下会进行填充到“固定码率”
     */
    int filler = 0;
    if( x264_ratecontrol_end( h, frame_size * 8, &filler ) < 0 )
        return -1;

    pic_out->hrd_timing = h->fenc->hrd_timing;
    pic_out->prop.f_crf_avg = h->fdec->f_crf_avg;

    /* Filler in AVC-Intra mode is written as zero bytes to the last slice
     * We don't know the size of the last slice until encapsulation so we add filler to the encapsulated NAL */
    if( h->param.i_avcintra_class )
    {
        if( check_encapsulated_buffer( h, h->thread[0], h->out.i_nal, frame_size, (int64_t)frame_size + filler ) < 0 )
            return -1;

        x264_nal_t *nal = &h->out.nal[h->out.i_nal-1];
        memset( nal->p_payload + nal->i_payload, 0, filler );
        nal->i_payload += filler;
        nal->i_padding = filler;
        frame_size += filler;

        /* Fix up the size header for mp4/etc */
        if( !h->param.b_annexb )
        {
            /* Size doesn't include the size of the header we're writing now. */
            uint8_t *nal_data = nal->p_payload;
            int chunk_size = nal->i_payload - 4;
            nal_data[0] = chunk_size >> 24;
            nal_data[1] = chunk_size >> 16;
            nal_data[2] = chunk_size >> 8;
            nal_data[3] = chunk_size >> 0;
        }
    }
    else
    {
        while( filler > 0 )
        {
            int f, overhead = FILLER_OVERHEAD - h->param.b_annexb;
            if( h->param.i_slice_max_size && filler > h->param.i_slice_max_size )
            {
                int next_size = filler - h->param.i_slice_max_size;
                int overflow = X264_MAX( overhead - next_size, 0 );
                f = h->param.i_slice_max_size - overhead - overflow;
            }
            else
                f = X264_MAX( 0, filler - overhead );

            if( bitstream_check_buffer_filler( h, f ) )
                return -1;
            nal_start( h, NAL_FILLER, NAL_PRIORITY_DISPOSABLE );
            x264_filler_write( h, &h->out.bs, f );
            if( nal_end( h ) )
                return -1;
            int total_size = encoder_encapsulate_nals( h, h->out.i_nal-1 );
            if( total_size < 0 )
                return -1;
            frame_size += total_size;
            filler -= total_size;
        }
    }

    /* End bitstream, set output  */
    // 输出
    *pi_nal = h->out.i_nal;  
    *pp_nal = h->out.nal;

    h->out.i_nal = 0;

    x264_noise_reduction_update( h );

    /* ---------------------- Compute/Print statistics --------------------- */
    thread_sync_stat( h, h->thread[0] );

    /* Slice stat */
    h->stat.i_frame_count[h->sh.i_type]++;
    h->stat.i_frame_size[h->sh.i_type] += frame_size;
    h->stat.f_frame_qp[h->sh.i_type] += h->fdec->f_qp_avg_aq;

    for( int i = 0; i < X264_MBTYPE_MAX; i++ )
        h->stat.i_mb_count[h->sh.i_type][i] += h->stat.frame.i_mb_count[i];
    for( int i = 0; i < 2; i++ )
        h->stat.i_mb_count_8x8dct[i] += h->stat.frame.i_mb_count_8x8dct[i];
    for( int i = 0; i < 6; i++ )
        h->stat.i_mb_cbp[i] += h->stat.frame.i_mb_cbp[i];
    for( int i = 0; i < 4; i++ )
        for( int j = 0; j < 13; j++ )
            h->stat.i_mb_pred_mode[i][j] += h->stat.frame.i_mb_pred_mode[i][j];
    if( h->sh.i_type != SLICE_TYPE_I )
    {
        for( int i = 0; i < X264_PARTTYPE_MAX; i++ )
            h->stat.i_mb_partition[h->sh.i_type][i] += h->stat.frame.i_mb_partition[i];
        for( int i_list = 0; i_list < 2; i_list++ )
            for( int i = 0; i < X264_REF_MAX*2; i++ )
                h->stat.i_mb_count_ref[h->sh.i_type][i_list][i] += h->stat.frame.i_mb_count_ref[i_list][i];
    }
    for( int i = 0; i < 3; i++ )
        h->stat.i_mb_field[i] += h->stat.frame.i_mb_field[i];
    if( h->sh.i_type == SLICE_TYPE_P && h->param.analyse.i_weighted_pred >= X264_WEIGHTP_SIMPLE )
    {
        h->stat.i_wpred[0] += !!h->sh.weight[0][0].weightfn;
        h->stat.i_wpred[1] += !!h->sh.weight[0][1].weightfn || !!h->sh.weight[0][2].weightfn;
    }
    if( h->sh.i_type == SLICE_TYPE_B )
    {
        h->stat.i_direct_frames[ h->sh.b_direct_spatial_mv_pred ] ++;
        if( h->mb.b_direct_auto_write )
        {
            //FIXME somewhat arbitrary time constants
            if( h->stat.i_direct_score[0] + h->stat.i_direct_score[1] > h->mb.i_mb_count )
                for( int i = 0; i < 2; i++ )
                    h->stat.i_direct_score[i] = h->stat.i_direct_score[i] * 9/10;
            for( int i = 0; i < 2; i++ )
                h->stat.i_direct_score[i] += h->stat.frame.i_direct_score[i];
        }
    }
    else
        h->stat.i_consecutive_bframes[h->fenc->i_bframes]++;

    psz_message[0] = '\0';
    double dur = h->fenc->f_duration;
    h->stat.f_frame_duration[h->sh.i_type] += dur;
    // 如果有开启psnr的话这里会做一些统计工作
    if( h->param.analyse.b_psnr )
    {
        int64_t ssd[3] =
        {
            h->stat.frame.i_ssd[0],
            h->stat.frame.i_ssd[1],
            h->stat.frame.i_ssd[2],
        };
        int luma_size = h->param.i_width * h->param.i_height;
        int chroma_size = CHROMA_SIZE( luma_size );
        pic_out->prop.f_psnr[0] = calc_psnr( ssd[0], luma_size );
        pic_out->prop.f_psnr[1] = calc_psnr( ssd[1], chroma_size );
        pic_out->prop.f_psnr[2] = calc_psnr( ssd[2], chroma_size );
        pic_out->prop.f_psnr_avg = calc_psnr( ssd[0] + ssd[1] + ssd[2], luma_size + chroma_size*2 );

        h->stat.f_ssd_global[h->sh.i_type]   += dur * (ssd[0] + ssd[1] + ssd[2]);
        h->stat.f_psnr_average[h->sh.i_type] += dur * pic_out->prop.f_psnr_avg;
        h->stat.f_psnr_mean_y[h->sh.i_type]  += dur * pic_out->prop.f_psnr[0];
        h->stat.f_psnr_mean_u[h->sh.i_type]  += dur * pic_out->prop.f_psnr[1];
        h->stat.f_psnr_mean_v[h->sh.i_type]  += dur * pic_out->prop.f_psnr[2];

        snprintf( psz_message, 80, " PSNR Y:%5.2f U:%5.2f V:%5.2f", pic_out->prop.f_psnr[0],
                                                                    pic_out->prop.f_psnr[1],
                                                                    pic_out->prop.f_psnr[2] );
    }
    // 如果开启了ssim的话这里会做一些统计的工作
    if( h->param.analyse.b_ssim )
    {
        pic_out->prop.f_ssim = h->stat.frame.f_ssim / h->stat.frame.i_ssim_cnt;
        h->stat.f_ssim_mean_y[h->sh.i_type] += pic_out->prop.f_ssim * dur;
        int msg_len = strlen(psz_message);
        snprintf( psz_message + msg_len, 80 - msg_len, " SSIM Y:%.5f", pic_out->prop.f_ssim );
    }
    psz_message[79] = '\0';

    x264_log( h, X264_LOG_DEBUG,
              "frame=%4d QP=%.2f NAL=%d Slice:%c Poc:%-3d I:%-4d P:%-4d SKIP:%-4d size=%d bytes%s\n",
              h->i_frame,
              h->fdec->f_qp_avg_aq,
              h->i_nal_ref_idc,
              h->sh.i_type == SLICE_TYPE_I ? 'I' : (h->sh.i_type == SLICE_TYPE_P ? 'P' : 'B' ),
              h->fdec->i_poc,
              h->stat.frame.i_mb_count_i,
              h->stat.frame.i_mb_count_p,
              h->stat.frame.i_mb_count_skip,
              frame_size,
              psz_message );

    // keep stats all in one place
    thread_sync_stat( h->thread[0], h );
    // for the use of the next frame
    thread_sync_stat( thread_current, h );

#ifdef DEBUG_MB_TYPE
{
    static const char mb_chars[] = { 'i', 'i', 'I', 'C', 'P', '8', 'S',
        'D', '<', 'X', 'B', 'X', '>', 'B', 'B', 'B', 'B', '8', 'S' };
    for( int mb_xy = 0; mb_xy < h->mb.i_mb_width * h->mb.i_mb_height; mb_xy++ )
    {
        if( h->mb.type[mb_xy] < X264_MBTYPE_MAX && h->mb.type[mb_xy] >= 0 )
            fprintf( stderr, "%c ", mb_chars[ h->mb.type[mb_xy] ] );
        else
            fprintf( stderr, "? " );

        if( (mb_xy+1) % h->mb.i_mb_width == 0 )
            fprintf( stderr, "\n" );
    }
}
#endif

    /* Remove duplicates, must be done near the end as breaks h->fref0 array
     * by freeing some of its pointers. */
    for( int i = 0; i < h->i_ref[0]; i++ )
        if( h->fref[0][i] && h->fref[0][i]->b_duplicate )
        {
            x264_frame_push_blank_unused( h, h->fref[0][i] );
            h->fref[0][i] = 0;
        }

    if( h->param.psz_dump_yuv )
        frame_dump( h );
    x264_emms();

    return frame_size;
}

```



### 参考引用

🐱‍🏍x264 github仓库：https://github.com/mirror/x264
